{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b99ff009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9328293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片和数据文件的路径\n",
    "image_dir = r\"E:\\picturedataplussssss1/\"\n",
    "train_data_file = r\"E:\\pic_diffusion_vae/train_data.xlsx\"\n",
    "test_data_file = r\"E:\\pic_diffusion_vae/test_data.xlsx\"\n",
    "\n",
    "# 读取 Excel 文件\n",
    "train_df = pd.read_excel(train_data_file, nrows=13000)\n",
    "test_df = pd.read_excel(test_data_file, nrows=3500)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_dir, dataframe):\n",
    "        self.images_dir = images_dir\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(224, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = f\"lcy{self.dataframe.iloc[idx, 0]}.jpg\"\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        conditions = torch.tensor(self.dataframe.iloc[idx, 3:4].values, dtype=torch.float)\n",
    "\n",
    "        \n",
    "        return {'pixel_values': image, 'input_ids': conditions}\n",
    "\n",
    "# 创建数据集实例\n",
    "#dataset = CustomDataset(image_dir, data_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(image_dir, train_df)\n",
    "test_dataset = CustomDataset(image_dir, test_df)\n",
    "\n",
    "\n",
    "# 设置设备（CPU 或 GPU）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# 创建 DataLoader\n",
    "#dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "# 获取并打印第一批数据的形状\n",
    "#for batch in dataloader:\n",
    "#    pixel_values = batch['pixel_values']\n",
    "#    input_ids = batch['input_ids']\n",
    "#    print(\"Batch pixel_values shape:\", pixel_values.shape)\n",
    "#    print(\"Batch input_ids shape:\", input_ids)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e89bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "# 定义 collate_fn 函数\n",
    "def collate_fn(data):\n",
    "    pixel_values = [i['pixel_values'] for i in data]\n",
    "    input_ids = [i['input_ids'] for i in data]\n",
    "\n",
    "    # 将列表的数据堆叠成一个新的Tensor，并转移到设备上\n",
    "    pixel_values = torch.stack(pixel_values).to(device)\n",
    "    input_ids = torch.stack(input_ids).to(device)\n",
    "    \n",
    "    return {'pixel_values': pixel_values, 'input_ids': input_ids}\n",
    "\n",
    "# 创建 DataLoader 实例\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, collate_fn=collate_fn, batch_size=64, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, collate_fn=collate_fn, batch_size=64, num_workers=0)\n",
    "\n",
    "# 创建 DataLoader 实例\n",
    "#loader = DataLoader(dataset,\n",
    "#                    shuffle=True,\n",
    "#                    collate_fn=collate_fn,\n",
    "#                    batch_size=32,\n",
    "#                    num_workers=0)  # 可以根据实际情况调整 num_workers|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274717a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.AvgPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.pool5 = nn.AvgPool2d(kernel_size=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # 计算池化后的尺寸（假设输入图像尺寸为224x224）\n",
    "        # 经过五次2x2的池化操作后，图像尺寸为 (224 / 2 / 2 / 2 / 2 / 2) = 7\n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "model = CNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53bedc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1150: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:30.)\n",
      "  return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=25088, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.requires_grad_(True)\n",
    "model.train()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0923ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 使用优化器中的weight_decay参数实现L2正则化\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.2)  # weight_decay用于L2正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003de6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 训练函数\n",
    "def train(model, criterion, optimizer, train_loader, test_loader, epochs=100, patience=40, r2_threshold=0.99, model_path=\"E:\\pic_diffusion_vae\\predictmodel/CNN_parametersC33Best.pth\"):\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "    best_r2 = -np.inf\n",
    "    best_epoch = -1\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            inputs, targets = batch['pixel_values'].to(device), batch['input_ids'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss = loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += total_loss.item()\n",
    "        \n",
    "        # 打印训练集上的损失、MAE和R²\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_mae = evaluate_mae(model, train_loader)\n",
    "        train_r2 = calculate_r2(model, train_loader)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Train MAE: {train_mae}, Train R²: {train_r2}')\n",
    "\n",
    "        # 测试集上的损失、MAE和R²\n",
    "        test_loss = evaluate_loss(model, criterion, test_loader)\n",
    "        test_mae = evaluate_mae(model, test_loader)\n",
    "        test_r2 = calculate_r2(model, test_loader)\n",
    "        print(f'Epoch {epoch+1}, Test Loss: {test_loss}, Test MAE: {test_mae}, Test R²: {test_r2}')\n",
    "\n",
    "        # 学习率调度器\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "        \n",
    "        # 保存最好的模型\n",
    "        if test_r2 > best_r2:\n",
    "            best_r2 = test_r2\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f'Saved Best Model at Epoch {epoch+1} with Test R²: {test_r2}')\n",
    "\n",
    "        # 早停法\n",
    "        if test_r2 >= r2_threshold:\n",
    "            print(f'Early stopping at Epoch {epoch+1} with Test R²: {test_r2}')\n",
    "            break\n",
    "\n",
    "        # 早停法的patience\n",
    "        if epoch - best_epoch > patience:\n",
    "            print(f'Early stopping at Epoch {epoch+1} due to no improvement for {patience} epochs')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7945f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mae(model, data_loader):\n",
    "    model.eval()\n",
    "    total_mae = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs, targets = batch['pixel_values'].to(device), batch['input_ids'].to(device)\n",
    "\n",
    "                \n",
    "            outputs = model(inputs)\n",
    "            mae = torch.mean(torch.abs(outputs - targets)/targets)\n",
    "            total_mae += mae.item()\n",
    "    return total_mae / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "389afb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估损失函数\n",
    "def evaluate_loss(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs, targets = batch['pixel_values'].to(device), batch['input_ids'].to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ef33ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算R²的函数\n",
    "def calculate_r2(model, data_loader):\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs, targets = batch['pixel_values'].to(device), batch['input_ids'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "    all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    return r2_score(all_targets, all_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1357b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.2843011670559645, Train MAE: 0.5650105233490467, Train R²: -0.5467519292199798\n",
      "Epoch 1, Test Loss: 1.9633615505695343, Test MAE: 0.5667852056026459, Test R²: -0.5429012255055117\n",
      "Saved Best Model at Epoch 1 with Test R²: -0.5429012255055117\n",
      "Epoch 2, Train Loss: 0.23803466038778423, Train MAE: 0.45425194561481474, Train R²: 0.4242146714614453\n",
      "Epoch 2, Test Loss: 0.7300956356525421, Test MAE: 0.4533817094564438, Test R²: 0.42621922129492207\n",
      "Saved Best Model at Epoch 2 with Test R²: 0.42621922129492207\n",
      "Epoch 3, Train Loss: 0.21417565075680614, Train MAE: 3.64252605676651, Train R²: -13.510277146753403\n",
      "Epoch 3, Test Loss: 18.447879486083984, Test MAE: 3.5744146585464476, Test R²: -13.48896480234911\n",
      "Epoch 4, Train Loss: 0.20592337675392627, Train MAE: 0.28280066899955275, Train R²: 0.6292930755552355\n",
      "Epoch 4, Test Loss: 0.4647530156373978, Test MAE: 0.28503994733095167, Test R²: 0.6347173471821712\n",
      "Saved Best Model at Epoch 4 with Test R²: 0.6347173471821712\n",
      "Epoch 5, Train Loss: 0.22253400968387724, Train MAE: 0.6026014670729637, Train R²: -0.654974556650854\n",
      "Epoch 5, Test Loss: 2.1018902373313906, Test MAE: 0.6005595695972442, Test R²: -0.6517321213486875\n",
      "Epoch 6, Train Loss: 0.19777257092297076, Train MAE: 0.628136046230793, Train R²: -0.7066976529015485\n",
      "Epoch 6, Test Loss: 2.167842926979065, Test MAE: 0.6242731058597565, Test R²: -0.7035469084513859\n",
      "Epoch 7, Train Loss: 0.19770695095881818, Train MAE: 0.2856457598507404, Train R²: 0.887412203838886\n",
      "Epoch 7, Test Loss: 0.1320042961835861, Test MAE: 0.28921646296978, Test R²: 0.8962549484397971\n",
      "Saved Best Model at Epoch 7 with Test R²: 0.8962549484397971\n",
      "Epoch 8, Train Loss: 0.1917675955593586, Train MAE: 0.5076629923284054, Train R²: -0.22565066504658393\n",
      "Epoch 8, Test Loss: 1.5560455906391144, Test MAE: 0.5085302639007568, Test R²: -0.22280686889174217\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "train(model, criterion, optimizer, train_loader, test_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d83f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存整个模型\n",
    "model_path = \"E:\\pic_diffusion_vae\\predictmodel/CNN_modelr.pth\"  # 替换为你的文件路径\n",
    "torch.save(model.to('cpu'), model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# 仅保存模型参数\n",
    "parameters_path = \"E:\\pic_diffusion_vae\\predictmodel/CNN_parametersr.pth\"  # 替换为你的文件路径\n",
    "torch.save(model.to('cpu').state_dict(), parameters_path)\n",
    "print(f\"Model parameters saved to {parameters_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "true_values = []\n",
    "predicted_values = []\n",
    "print(len(test_loader))\n",
    "# 遍历测试数据集并收集真实值和预测值\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, targets = batch['pixel_values'].to(device), batch['input_ids'].to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        output = model(inputs)\n",
    "        \n",
    "        # 将输出从Tensor转换为numpy数组并收集\n",
    "        predicted_values.extend(output.cpu().numpy())\n",
    "        true_values.extend(targets.cpu().numpy())\n",
    "\n",
    "# 绘制得分曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(true_values, predicted_values, alpha=0.5, label='Predict vs True', edgecolors='k')\n",
    "plt.plot([min(true_values), max(true_values)], [min(true_values), max(true_values)], 'r--', label='理想线')\n",
    "plt.xlabel('True', fontsize=12)\n",
    "plt.ylabel('Predict', fontsize=12)\n",
    "plt.title('CNN_Predict', fontsize=15)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 调整布局以确保标签显示完整\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab3bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
