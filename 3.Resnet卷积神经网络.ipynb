{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8c15a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47adafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片路径\n",
    "image_folder = \"E:\\shujuji\\metamaterialpicture900features\"\n",
    "# Excel文件路径\n",
    "excel_path = \"E:\\\\1-1000-90.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12684a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(excel_path, usecols=[0, 16])  # 使用第1列和第17列的数据，从0开始计数，并跳过第一行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b904f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化图像和性能数组\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2f73c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 651):\n",
    "    img_path = os.path.join(image_folder, f\"lcy{i}.jpg\")\n",
    "    if i in df[\"编号\"].values:\n",
    "        img = load_img(img_path, target_size=(20, 20))  # 调整为合适的图像大小\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = cv2.cvtColor(img_array.astype('uint8'), cv2.COLOR_RGB2GRAY)\n",
    "        X.append(img_array)\n",
    "y=df[\"d33\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b621a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为NumPy数组\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f67012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片路径\n",
    "image_folder1 = \"E:\\metamaterialpicture\\metamaterialpicture900features\"\n",
    "# Excel文件路径\n",
    "excel_path1 = \"E:\\metamaterialpicture\\metamaterialpicture90\\\\1-430-90.xlsx\"\n",
    "df1 = pd.read_excel(excel_path1, usecols=[0, 13])  # 使用第1列和第17列的数据，从0开始计数，并跳过第一行\n",
    "# 初始化图像和性能数组\n",
    "X1 = []\n",
    "y1 = []\n",
    "for i in range(1, 431):\n",
    "    img_path = os.path.join(image_folder1, f\"lcy{i}.jpg\")\n",
    "    if i in df1[\"编号\"].values:\n",
    "        img = load_img(img_path, target_size=(20, 20))  # 调整为合适的图像大小\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = cv2.cvtColor(img_array.astype('uint8'), cv2.COLOR_RGB2GRAY)\n",
    "        X1.append(img_array)\n",
    "\n",
    "y1=df1[\"d33\"]\n",
    "# 转换为NumPy数组\n",
    "X1 = np.array(X1)\n",
    "y1 = np.array(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f81f6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片路径\n",
    "image_folder2 = \"E:\\metamaterialpicture\\me90features\"\n",
    "# Excel文件路径\n",
    "excel_path2 = \"E:\\metamaterialpicture\\me90\\\\1-300-90.xlsx\"\n",
    "df2 = pd.read_excel(excel_path2, usecols=[0, 14])  # 使用第1列和第17列的数据，从0开始计数，并跳过第一行\n",
    "# 初始化图像和性能数组\n",
    "X2 = []\n",
    "y2 = []\n",
    "for i in range(1, 302):\n",
    "    img_path = os.path.join(image_folder2, f\"lcy{i}.jpg\")\n",
    "    if i in df2[\"编号\"].values:\n",
    "        img = load_img(img_path, target_size=(20, 20))  # 调整为合适的图像大小\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = cv2.cvtColor(img_array.astype('uint8'), cv2.COLOR_RGB2GRAY)\n",
    "        X2.append(img_array)\n",
    "\n",
    "y2=df2[\"d33\"]\n",
    "# 转换为NumPy数组\n",
    "X2 = np.array(X2)\n",
    "y2 = np.array(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "224687fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1056, 20, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和测试集\n",
    "X3=np.concatenate((X, X1), axis=0)\n",
    "y3=np.concatenate((y, y1), axis=0)\n",
    "X4=np.concatenate((X3, X2), axis=0)\n",
    "y4=np.concatenate((y3, y2), axis=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, y4, test_size=0.2, random_state=500)\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "362d5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义ResNet的基本块\n",
    "class BasicBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters, kernel_size=3, strides=stride, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "        self.conv2 = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.downsample = None\n",
    "        if stride != 1:\n",
    "            self.downsample = models.Sequential([\n",
    "                layers.Conv2D(filters, kernel_size=1, strides=stride, use_bias=False),\n",
    "                layers.BatchNormalization()\n",
    "            ])\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        identity = inputs\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(inputs)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# 定义ResNet模型\n",
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self, block, layer, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=7, strides=2, padding='same', use_bias=False, input_shape=(20,20,1))\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "        self.Averagepool = layers.AveragePooling2D(pool_size=(3, 3), strides=2, padding='same')\n",
    "        self.layer1 = self.build_layer(block, 64, layer[0])\n",
    "        self.layer2 = self.build_layer(block, 128, layer[1], stride=2)\n",
    "        self.layer3 = self.build_layer(block, 256, layer[2], stride=2)\n",
    "        self.layer4 = self.build_layer(block, 512, layer[3], stride=2)\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classes, activation='linear')  # 线性激活函数，用于回归问题\n",
    "\n",
    "    def build_layer(self, block, filters, blocks, stride=1):\n",
    "        res_blocks = models.Sequential()\n",
    "        res_blocks.add(block(filters, stride=stride))\n",
    "        for _ in range(1, blocks):\n",
    "            res_blocks.add(block(filters, stride=1))\n",
    "        return res_blocks\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = self.layer1(x, training=training)\n",
    "        x = self.layer2(x, training=training)\n",
    "        x = self.layer3(x, training=training)\n",
    "        x = self.layer4(x, training=training)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 创建ResNet-18模型\n",
    "resnet18 = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=1)\n",
    "\n",
    "# 编译模型，选择合适的优化器和损失函数\n",
    "resnet18.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adc18289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\__autograph_generated_file9d2pau73.py\", line 14, in tf__call\n        x = ag__.converted_call(ag__.ld(self).layer1, (ag__.ld(x),), dict(training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\__autograph_generated_filehdn3ejww.py\", line 11, in tf__call\n        x = ag__.converted_call(ag__.ld(self).conv1, (ag__.ld(inputs),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'res_net_3' (type ResNet).\n    \n    in user code:\n    \n        File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_12812\\724000210.py\", line 59, in call  *\n            x = self.layer1(x, training=training)\n        File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\__autograph_generated_filehdn3ejww.py\", line 11, in tf__call\n            x = ag__.converted_call(ag__.ld(self).conv1, (ag__.ld(inputs),), None, fscope)\n    \n        ValueError: Exception encountered when calling layer 'basic_block_24' (type BasicBlock).\n        \n        in user code:\n        \n            File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_12812\\724000210.py\", line 19, in call  *\n                x = self.conv1(inputs)\n            File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 251, in assert_input_compatibility\n                f'Input {input_index} of layer \"{layer_name}\" '\n        \n            ValueError: Input 0 of layer \"conv2d_61\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 64)\n        \n        \n        Call arguments received by layer 'basic_block_24' (type BasicBlock):\n          • inputs=tf.Tensor(shape=(None, 64), dtype=float32)\n          • training=True\n    \n    \n    Call arguments received by layer 'res_net_3' (type ResNet):\n      • inputs=tf.Tensor(shape=(None, 20, 20, 1), dtype=float32)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12812\\65446896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 在 model.fit 中使用 callbacks 参数将 LearningRateScheduler 加入训练过程\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file9d2pau73.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filehdn3ejww.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0midentity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\__autograph_generated_file9d2pau73.py\", line 14, in tf__call\n        x = ag__.converted_call(ag__.ld(self).layer1, (ag__.ld(x),), dict(training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\__autograph_generated_filehdn3ejww.py\", line 11, in tf__call\n        x = ag__.converted_call(ag__.ld(self).conv1, (ag__.ld(inputs),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'res_net_3' (type ResNet).\n    \n    in user code:\n    \n        File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_12812\\724000210.py\", line 59, in call  *\n            x = self.layer1(x, training=training)\n        File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\__autograph_generated_filehdn3ejww.py\", line 11, in tf__call\n            x = ag__.converted_call(ag__.ld(self).conv1, (ag__.ld(inputs),), None, fscope)\n    \n        ValueError: Exception encountered when calling layer 'basic_block_24' (type BasicBlock).\n        \n        in user code:\n        \n            File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_12812\\724000210.py\", line 19, in call  *\n                x = self.conv1(inputs)\n            File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"D:\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 251, in assert_input_compatibility\n                f'Input {input_index} of layer \"{layer_name}\" '\n        \n            ValueError: Input 0 of layer \"conv2d_61\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 64)\n        \n        \n        Call arguments received by layer 'basic_block_24' (type BasicBlock):\n          • inputs=tf.Tensor(shape=(None, 64), dtype=float32)\n          • training=True\n    \n    \n    Call arguments received by layer 'res_net_3' (type ResNet):\n      • inputs=tf.Tensor(shape=(None, 20, 20, 1), dtype=float32)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "# 在 model.fit 中使用 callbacks 参数将 LearningRateScheduler 加入训练过程\n",
    "history = resnet18.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'][5:], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'][5:], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练集上计算 R² 分数\n",
    "y_train_pred = resnet18.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# 在验证集上计算 R² 分数\n",
    "y_test_pred = resnet18.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# 打印 R² 分数\n",
    "print(f'R² 分数 - 训练集: {r2_train:.4f}')\n",
    "print(f'R² 分数 - 验证集: {r2_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d463490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
