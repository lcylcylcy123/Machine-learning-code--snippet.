{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f68f0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.utils.random import check_random_state\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c197f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    16.03          248.675       23          120.259              N/A      7.00m\n",
      "   1    13.99          249.215       16          63.4758              N/A      7.36m\n",
      "   2    27.14          341.358       25          44.9228              N/A      8.52m\n",
      "   3    12.37          467.477       27          44.8597              N/A      7.21m\n",
      "   4     2.11          272.138        7          67.2812              N/A      6.18m\n",
      "   5     2.52          465.511        8          66.9506              N/A      7.15m\n",
      "   6     1.41          246.866       20          215.105              N/A      6.01m\n",
      "   7     1.69          247.294       28          174.123              N/A      5.85m\n",
      "   8     7.48          254.387       11          89.2693              N/A      6.40m\n",
      "   9    13.05          464.151        8          55.0732              N/A      6.87m\n",
      "  10     5.16          1335.53       10          54.0059              N/A      6.22m\n",
      "  11     1.45          246.848        3          215.086              N/A      5.63m\n",
      "  12     2.32          248.647        7          161.832              N/A      6.48m\n",
      "  13     3.19          353.917        7          76.0033              N/A      5.89m\n",
      "  14     1.44          246.793        3          215.086              N/A      5.42m\n",
      "  15     2.17          246.013       10          135.745              N/A      5.51m\n",
      "  16     3.52          353.058        9          63.1865              N/A      5.74m\n",
      "  17     1.47          247.043        3          194.562              N/A      5.27m\n",
      "  18     2.29          253.826        9          75.0306              N/A      5.33m\n",
      "  19     3.29           378.31        9          75.0306              N/A      5.51m\n",
      "  20     1.50          246.448        3          194.562              N/A      5.95m\n",
      "  21     4.62          267.506        6          67.1957              N/A      5.41m\n",
      "  22     3.58           364.74        6          67.1957              N/A      5.31m\n",
      "  23     1.57          244.309        9          126.032              N/A      4.89m\n",
      "  24     4.13          293.817        7          118.185              N/A      5.20m\n",
      "  25     3.54          393.279        8          68.2239              N/A      5.14m\n",
      "  26     1.57          244.837        3          193.544              N/A      4.73m\n",
      "  27     4.28          282.404        5            73.34              N/A      5.01m\n",
      "  28     3.53          384.273        3            72.04              N/A      5.70m\n",
      "  29     1.53          244.549        3            72.04              N/A      4.54m\n",
      "  30     4.48          313.947        6          56.3659              N/A      4.78m\n",
      "  31     3.55          1235.38        6          56.3659              N/A      4.71m\n",
      "  32     1.56          244.701       11          68.1704              N/A      4.41m\n",
      "  33     2.61          1676.46        6          54.6665              N/A      4.50m\n",
      "  34     1.38          246.833       14          235.949              N/A      4.20m\n",
      "  35     1.66           246.73        3          183.396              N/A      4.16m\n",
      "  36     4.20          245.389       12          73.4666              N/A      4.99m\n",
      "  37     8.80          271.409       12            56.31              N/A      4.57m\n",
      "  38     6.19          1028.57       13          49.2609              N/A      4.42m\n",
      "  39     1.78          244.501        3           86.238              N/A      3.96m\n",
      "  40     3.12          613.507        3           86.238              N/A      4.06m\n",
      "  41     1.39          244.975        5          76.1636              N/A      3.76m\n",
      "  42     5.45          305.165       14          68.7429              N/A      4.00m\n",
      "  43     3.45          1744.85       12          47.5773              N/A      3.90m\n",
      "  44     1.49          243.929        3           86.238              N/A      4.19m\n",
      "  45     5.85          381.736        5          69.6047              N/A      3.85m\n",
      "  46     4.47          1541.58       20          61.1356              N/A      3.76m\n",
      "  47     1.68          266.192        5          77.3362              N/A      3.42m\n",
      "  48     3.08          1349.01        5          81.0781              N/A      3.53m\n",
      "  49     1.42          245.889        3           86.238              N/A      3.28m\n",
      "  50     4.97          241.865       10          69.5094              N/A      3.44m\n",
      "  51     3.21          1320.39       11           68.033              N/A      3.34m\n",
      "  52     1.40          246.438        3           86.238              N/A      3.62m\n",
      "  53     3.91           244.34        6          69.5765              N/A      3.15m\n",
      "  54     4.03          587.313        6          57.7074              N/A      3.15m\n",
      "  55     3.25          1790.53        5          76.0619              N/A      3.08m\n",
      "  56     1.50          244.251        3           86.238              N/A      2.82m\n",
      "  57     2.38          576.996       12          82.4964              N/A      2.85m\n",
      "  58     1.41          246.831       14          209.747              N/A      2.72m\n",
      "  59     1.65           246.68        5          71.6181              N/A      2.64m\n",
      "  60     4.64          245.886        5          69.0412              N/A      2.71m\n",
      "  61     7.66          249.685       16          55.2509              N/A      3.28m\n",
      "  62     8.57          704.086       12          40.6586              N/A      2.80m\n",
      "  63     2.69          352.274        6          60.5217              N/A      2.50m\n",
      "  64     1.40          246.802        7          155.028              N/A      2.31m\n",
      "  65     1.87          246.525        9          54.5776              N/A      2.26m\n",
      "  66     5.71          247.623        9          54.5776              N/A      2.35m\n",
      "  67     5.10           373.37        9          54.5776              N/A      2.31m\n",
      "  68     1.47          243.445        3          88.2611              N/A      2.08m\n",
      "  69     5.59          805.084        4          54.0178              N/A      2.17m\n",
      "  70    13.16          3305.47       22          36.8471              N/A      2.65m\n",
      "  71    48.32          307.146       43          46.9586              N/A      2.97m\n",
      "  72    38.88           582.27       50            33.14              N/A      2.66m\n",
      "  73    13.61          1393.44       36          33.1243              N/A      2.08m\n",
      "  74     4.17          5609.47        7          36.8642              N/A      1.80m\n",
      "  75     1.57          250.901        4          54.0178              N/A      1.62m\n",
      "  76     2.27          1499.28        4          54.0178              N/A      1.59m\n",
      "  77     1.45          246.856       12          204.939              N/A      1.48m\n",
      "  78     1.92          246.578       10          139.607              N/A      1.42m\n",
      "  79     6.45          246.267       10           71.804              N/A      1.45m\n",
      "  80     8.57          382.619       12          67.1246              N/A      1.67m\n",
      "  81     3.42          520.213        6          59.1742              N/A      1.28m\n",
      "  82     1.43          246.676       37          138.998              N/A      1.14m\n",
      "  83     3.37          245.275       37          102.171              N/A      1.11m\n",
      "  84     5.33          344.381       15          66.4536              N/A      1.10m\n",
      "  85     3.52          577.791       10          49.8422              N/A      1.01m\n",
      "  86     1.57          244.729        3          131.715              N/A     53.17s\n",
      "  87     2.94          317.329        5          68.0415              N/A     50.80s\n",
      "  88     3.22          523.986        5          68.0415              N/A     47.29s\n",
      "  89     1.51          243.751        3          131.715              N/A     48.36s\n",
      "  90     4.52           459.47        6          67.9181              N/A     39.14s\n",
      "  91     3.32          1022.66        6          67.9181              N/A     36.58s\n",
      "  92     1.54          244.877        3          131.715              N/A     29.37s\n",
      "  93     2.46          421.574       20          56.6337              N/A     25.34s\n",
      "  94     1.43          246.814       35          222.082              N/A     20.49s\n",
      "  95     2.20          246.612        7          207.682              N/A     16.54s\n",
      "  96     8.81          244.803       24          68.6841              N/A     13.60s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  97    21.38          248.219        8          66.9169              N/A     10.45s\n",
      "  98    17.59          538.617       35          53.1476              N/A      5.90s\n",
      "  99     6.25          958.394        8          44.3748              N/A      0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>div(mul(div(0.562, 0.052), sin(X0)), 0.028)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SymbolicRegressor</label><div class=\"sk-toggleable__content\"><pre>div(mul(div(0.562, 0.052), sin(X0)), 0.028)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SymbolicRegressor(function_set=['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
       "                                'sin', 'cos'],\n",
       "                  generations=100, max_samples=1, p_crossover=0.8,\n",
       "                  p_subtree_mutation=0.1, parsimony_coefficient='auto',\n",
       "                  population_size=10000, random_state=0, stopping_criteria=1,\n",
       "                  verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = check_random_state(0)\n",
    " \n",
    "# Training samples\n",
    "X_train = [[0],[0.2],[0.5],[0.6],[0.8],[1],[1.2],[1.5],[1.8],[2],[2.5]]\n",
    "y_train = [[0],[10],[60],[160],[310],[340],[350],[374],[374],[374],[374]]\n",
    "#Testing samples\n",
    "X_test = X_train\n",
    "y_test = y_train\n",
    "functions.make_function()\n",
    "function_set = ['add', 'sub', 'mul', 'div',\n",
    "            'sqrt', 'log', 'sin', 'cos']\n",
    "est_gp = SymbolicRegressor(population_size=10000,function_set=function_set,\n",
    "                           generations=100, stopping_criteria=1,\n",
    "                           p_crossover=0.8, p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.01, p_point_mutation=0.01,\n",
    "                           max_samples=1, verbose=1,\n",
    "                           parsimony_coefficient='auto', random_state=0)\n",
    "est_gp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf584d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub(add(-0.999, X1), mul(sub(X1, X0), add(X0, X1)))\n"
     ]
    }
   ],
   "source": [
    "print(est_gp._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5111c18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
